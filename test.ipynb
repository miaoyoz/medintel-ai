{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于测试功能的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok1\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(f\"ok{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前进度：100.00%"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import xlwt\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def ask_url(url):\n",
    "    head = {    \n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47\"\n",
    "        # \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36 Edg/86.0.622.63\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, headers=head, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = 'utf-8'\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def get_data(base_url):\n",
    "    data_list = []\n",
    "    \n",
    "    # 遍历每一页\n",
    "    for i in range(0, 1):\n",
    "        url = base_url + f\"p{i + 1}/\"\n",
    "        html = ask_url(url)\n",
    "        if html == \"\":\n",
    "            continue\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "        # 遍历每一种疾病\n",
    "        for item in soup.find_all('div', class_=\"result_item\"):\n",
    "            data = {}\n",
    "            if item.div.p.span.string == \"疾病\":\n",
    "                # diseaseName\n",
    "                data['diseaseName'] = item.div.p.a.string\n",
    "                \n",
    "                # diseaseAlias\n",
    "                # data.append(item.div.p.span.string.strip('（）'))\n",
    "                \n",
    "                # symptom\n",
    "                symptoms = []\n",
    "                p = item.find('p', class_='result_item_content_label')\n",
    "                for symptom in p.find_all('a'):\n",
    "                    symptoms.append(symptom.string)\n",
    "                \n",
    "                # https://jbk.39.net/zs/\n",
    "                sub_url = item.div.p.a.attrs[\"href\"]\n",
    "                sub_html = ask_url(sub_url)\n",
    "                if sub_html == \"\":\n",
    "                    continue\n",
    "                sub_soup = BeautifulSoup(sub_html, 'html.parser')\n",
    "                \n",
    "                information_ul = sub_soup.find('ul', class_=\"information_ul\")\n",
    "                for detail in information_ul.find_all('li'):\n",
    "                    if detail.i.string == '别名：':\n",
    "                        data['diseaseAlias'] = detail.span.string\n",
    "                    elif detail.i.string == '发病部位：':\n",
    "                        data['siteOfOnset'] = []\n",
    "                        for site in detail.span.find_all('a'):\n",
    "                            data['siteOfOnset'].append(site.string)\n",
    "                    elif detail.i.string == '传染性：':\n",
    "                        data['infectivity'] = detail.span.string\n",
    "                    elif detail.i.string == '多发人群：':\n",
    "                        data['multiplePopulation'] = detail.span.string\n",
    "                    elif detail.i.string == '并发症：':\n",
    "                        data['complication'] = []\n",
    "                        for complication in detail.span.find_all('a'):\n",
    "                            data['complication'].append(complication.string)\n",
    "                    elif detail.i.string == '挂号科室：':\n",
    "                        data['registrationDepartment'] = []\n",
    "                        for department in detail.span.find_all('a'):\n",
    "                            data['registrationDepartment'].append(department.string)\n",
    "                    elif detail.i.string == '临床检查：':\n",
    "                        data['clinicalExamination'] = []\n",
    "                        for examination in detail.span.find_all('a'):\n",
    "                            data['clinicalExamination'].append(examination.string)\n",
    "                    elif detail.i.string == '典型症状：':\n",
    "                        for symptom in detail.span.find_all('a'):\n",
    "                            symptoms.append(symptom.string)\n",
    "                        data['commonDrugs'] = symptoms\n",
    "                \n",
    "                information_ul1 = sub_soup.find('ul', class_=\"information_ul information_ul_bottom\")\n",
    "                for detail in information_ul1.find_all('li'):\n",
    "                    if detail.i.string == '常用药品：':\n",
    "                        data['commonDrugs'] = []\n",
    "                        for drug in detail.span.find_all('a'):\n",
    "                            data['commonDrugs'].append(drug.string)\n",
    "\n",
    "            data_list.append(data)\n",
    "            \n",
    "    return data_list\n",
    "\n",
    "\n",
    "def save_data(data_list, save_path):\n",
    "    book = xlwt.Workbook(encoding='utf-8', style_compression=0)\n",
    "    sheet = book.add_sheet(\"智能诊断数据集\", cell_overwrite_ok=True)\n",
    "    col = (\"diseaseName\", \"diseaseAlias\", \"siteOfOnset\", \"infectivity\", \"multiplePopulation\", \"earlySymptom\", \"advancedSymptom\", \"complication\", \"registrationDepartment\", \"clinicalExamination\", \"commonDrugs\")\n",
    "    length = len(data_list)\n",
    "    for i in range(0, 11):\n",
    "        sheet.write(0, i, col[i])\n",
    "    for i in range(0, length):\n",
    "        print(\"\\r当前进度：{:.2f}%\".format((i + 1) * 100 / length), end=\"\")\n",
    "        data = data_list[i]\n",
    "        for j in range(0, 11):\n",
    "            if col[j] in data:\n",
    "                sheet.write(i + 1, j, data[col[j]])\n",
    "    book.save(save_path)\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://jbk.39.net/bw/\"\n",
    "    save_path = \".\\\\智能诊断数据集.xls\"\n",
    "    # html = ask_url(base_url)\n",
    "    \n",
    "    data_list = get_data(base_url)\n",
    "    save_data(data_list, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['器质性早泄', '男子性功能障碍', '心理性性功能障碍', '遗精滑泄', '详细']\n",
      "['湿疣', '外阴鳞状上皮疣状增生', '出血性丘疹', '溃疡分泌物恶臭', '乳头状肿物', '详细']\n",
      "['椎间盘退行性变', '腰脊椎疼痛', '惧站立，喜依托', '胸腰段及腰椎前凸消失', '根性坐骨神经痛', '详细']\n",
      "['静脉曲张性外痔', '痔出血', '便血鲜红', '排便障碍', '炎性外痔', '详细']\n",
      "['心理性性功能障碍', '男子性功能障碍', '雄激素过少', '精冷不育', '脉涩或结', '详细']\n",
      "['乳腺隐痛', '结节', '囊肿', '经期前乳房痛', '腋窝痛', '详细']\n",
      "['劳动耐力下降', '胸骨后疼痛', '胸闷', '劳累后心悸', '阵发性夜间呼吸困难', '详细']\n",
      "['转氨酶增高', '肝肿大', '乙肝表面抗原（HBsAg）阳性', '乙肝e抗原（HBeAg）阳性', '肝功能异常', '详细']\n",
      "['不明原因发热', '免疫力降低', 'HIV感染', '反复感染', '关节疼痛', '详细']\n",
      "['剧痒', '风团', '皮肤有压痕', '斑丘疹', '丘疹', '详细']\n",
      "['第1跖趾关节疼痛和肿大', '关节疼痛', '关节肿胀', '关节畸形', '尿酸盐在关节内沉积增多', '详细']\n",
      "['腰部钝痛', '肾盏结石', '肾区叩击痛', '排出结石', '腰部包块', '详细']\n",
      "['胃酸过多', '食欲较差', '腹胀嗳腐', '胃胀', '胃气上逆', '详细']\n",
      "['口腔粘膜弥漫充血', '口舌生疮', '口腔痛', '溃疡', '容易上火', '详细']\n",
      "['阴道分泌物增多', '排尿时外阴灼热、瘙痒或疼痛', '性交疼痛', '阴部灼热', '白带增多', '详细']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def ask_url(url):\n",
    "    head = {    \n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47\"\n",
    "        # \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36 Edg/86.0.622.63\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, headers=head, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = 'utf-8'\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "for i in range(0, 1):\n",
    "            url = \"https://jbk.39.net/bw/\" + f\"p{i + 1}/\"\n",
    "            html = ask_url(url)\n",
    "            if html == \"\":\n",
    "                continue\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "            # 遍历每一种疾病\n",
    "            for item in soup.find_all('div', class_=\"result_item\"):\n",
    "                if item.div.p.span.string == \"疾病\":\n",
    "                    # 疾病url\n",
    "                    disease_url = item.div.p.a.attrs[\"href\"]\n",
    "                    \n",
    "                    # 疾病简介\n",
    "                    disease_jianjie_url = disease_url + \"jbzs/\" \n",
    "                    jianjie_html = ask_url(disease_jianjie_url)\n",
    "                    if jianjie_html == \"\":\n",
    "                        continue\n",
    "                    jianjie_soup = BeautifulSoup(jianjie_html, 'html.parser')\n",
    "                    name = jianjie_soup.find('div', class_=\"disease\").h1.string\n",
    "                    # print(name)\n",
    "                    jianjie = jianjie_soup.find('p', class_=\"introduction\").string\n",
    "                    # print(jianjie)\n",
    "                    for disease_basic in jianjie_soup.find_all('ul', class_=\"disease_basic\"):\n",
    "                        for li in disease_basic.find_all('li'):\n",
    "                            if li.span.string == \"就诊科室：\":\n",
    "                                span = li.find_all('span')[1]\n",
    "                                category = \"\"\n",
    "                                for a in span.find_all('a'):\n",
    "                                    category += a.string + \",\"\n",
    "                                    department_url = a.attrs[\"href\"]\n",
    "                                    department_html = ask_url(department_url)\n",
    "                                    if department_html == \"\":\n",
    "                                        continue\n",
    "                                    department_soup = BeautifulSoup(department_html, 'html.parser')\n",
    "                                category = category[:-1]\n",
    "                                # print(category)    \n",
    "                            elif li.span.string == \"相关症状：\":\n",
    "                                span = li.find_all('span')[1]\n",
    "                                symptom = []\n",
    "                                for a in span.find_all('a'):\n",
    "                                    symptom_name = a.string\n",
    "                                    symptom.append(symptom_name)\n",
    "                                    \n",
    "                                    \n",
    "                                # symptom = symptom[:-1]\n",
    "                                print(symptom) \n",
    "                                \n",
    "                            \n",
    "                           \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "str = \"1,2,3,4,5,\"\n",
    "list = str.split(\",\")\n",
    "print(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item,index in enumerate(list):\n",
    "    print(item,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "插入成功\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "conn = pymongo.MongoClient('localhost', 27017) # 连接数据库\n",
    "db = conn['medintel'] # 建立数据库\n",
    "col = db['test'] # 建表，字典形式\n",
    "\n",
    "data = {\n",
    "    'name': '张三',\n",
    "    'age': 18,\n",
    "}\n",
    "col.insert_one(data) # 插入数据\n",
    "print('插入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
