{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于测试功能的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok1\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "print(f\"ok{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前进度：100.00%"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['器质性早泄', '男子性功能障碍', '心理性性功能障碍', '遗精滑泄', '详细']\n",
      "['湿疣', '外阴鳞状上皮疣状增生', '出血性丘疹', '溃疡分泌物恶臭', '乳头状肿物', '详细']\n",
      "['椎间盘退行性变', '腰脊椎疼痛', '惧站立，喜依托', '胸腰段及腰椎前凸消失', '根性坐骨神经痛', '详细']\n",
      "['静脉曲张性外痔', '痔出血', '便血鲜红', '排便障碍', '炎性外痔', '详细']\n",
      "['心理性性功能障碍', '男子性功能障碍', '雄激素过少', '精冷不育', '脉涩或结', '详细']\n",
      "['乳腺隐痛', '结节', '囊肿', '经期前乳房痛', '腋窝痛', '详细']\n",
      "['劳动耐力下降', '胸骨后疼痛', '胸闷', '劳累后心悸', '阵发性夜间呼吸困难', '详细']\n",
      "['转氨酶增高', '肝肿大', '乙肝表面抗原（HBsAg）阳性', '乙肝e抗原（HBeAg）阳性', '肝功能异常', '详细']\n",
      "['不明原因发热', '免疫力降低', 'HIV感染', '反复感染', '关节疼痛', '详细']\n",
      "['剧痒', '风团', '皮肤有压痕', '斑丘疹', '丘疹', '详细']\n",
      "['第1跖趾关节疼痛和肿大', '关节疼痛', '关节肿胀', '关节畸形', '尿酸盐在关节内沉积增多', '详细']\n",
      "['腰部钝痛', '肾盏结石', '肾区叩击痛', '排出结石', '腰部包块', '详细']\n",
      "['胃酸过多', '食欲较差', '腹胀嗳腐', '胃胀', '胃气上逆', '详细']\n",
      "['口腔粘膜弥漫充血', '口舌生疮', '口腔痛', '溃疡', '容易上火', '详细']\n",
      "['阴道分泌物增多', '排尿时外阴灼热、瘙痒或疼痛', '性交疼痛', '阴部灼热', '白带增多', '详细']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def ask_url(url):\n",
    "    head = {    \n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47\"\n",
    "        # \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36 Edg/86.0.622.63\"\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, headers=head, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = 'utf-8'\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "for i in range(0, 1):\n",
    "            url = \"https://jbk.39.net/bw/\" + f\"p{i + 1}/\"\n",
    "            html = ask_url(url)\n",
    "            if html == \"\":\n",
    "                continue\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "            # 遍历每一种疾病\n",
    "            for item in soup.find_all('div', class_=\"result_item\"):\n",
    "                if item.div.p.span.string == \"疾病\":\n",
    "                    # 疾病url\n",
    "                    disease_url = item.div.p.a.attrs[\"href\"]\n",
    "                    \n",
    "                    # 疾病简介\n",
    "                    disease_jianjie_url = disease_url + \"jbzs/\" \n",
    "                    jianjie_html = ask_url(disease_jianjie_url)\n",
    "                    if jianjie_html == \"\":\n",
    "                        continue\n",
    "                    jianjie_soup = BeautifulSoup(jianjie_html, 'html.parser')\n",
    "                    name = jianjie_soup.find('div', class_=\"disease\").h1.string\n",
    "                    # print(name)\n",
    "                    jianjie = jianjie_soup.find('p', class_=\"introduction\").string\n",
    "                    # print(jianjie)\n",
    "                    for disease_basic in jianjie_soup.find_all('ul', class_=\"disease_basic\"):\n",
    "                        for li in disease_basic.find_all('li'):\n",
    "                            if li.span.string == \"就诊科室：\":\n",
    "                                span = li.find_all('span')[1]\n",
    "                                category = \"\"\n",
    "                                for a in span.find_all('a'):\n",
    "                                    category += a.string + \",\"\n",
    "                                    department_url = a.attrs[\"href\"]\n",
    "                                    department_html = ask_url(department_url)\n",
    "                                    if department_html == \"\":\n",
    "                                        continue\n",
    "                                    department_soup = BeautifulSoup(department_html, 'html.parser')\n",
    "                                category = category[:-1]\n",
    "                                # print(category)    \n",
    "                            elif li.span.string == \"相关症状：\":\n",
    "                                span = li.find_all('span')[1]\n",
    "                                symptom = []\n",
    "                                for a in span.find_all('a'):\n",
    "                                    symptom_name = a.string\n",
    "                                    symptom.append(symptom_name)\n",
    "                                    \n",
    "                                    \n",
    "                                # symptom = symptom[:-1]\n",
    "                                print(symptom) \n",
    "                                \n",
    "                            \n",
    "                           \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "str = \"1,2,3,4,5,\"\n",
    "list = str.split(\",\")\n",
    "print(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item,index in enumerate(list):\n",
    "    print(item,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "插入成功\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "conn = pymongo.MongoClient('localhost', 27017) # 连接数据库\n",
    "db = conn['medintel'] # 建立数据库\n",
    "col = db['test'] # 建表，字典形式\n",
    "\n",
    "data = {\n",
    "    'name': '张三',\n",
    "    'age': 18,\n",
    "}\n",
    "col.insert_one(data) # 插入数据\n",
    "print('插入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for item in range(0, 10):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdsd is in the list\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset/data/test.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    if 'asdsd\\n' in lines:\n",
    "        print(\"asdsd is in the list\")\n",
    "    else:\n",
    "        print(\"asdsd is not in the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "conn = pymongo.MongoClient('localhost', 27017) \n",
    "db = conn['medintel'] \n",
    "col = db['data'] \n",
    "data = col.find()\n",
    "\n",
    "\n",
    "with open(\"dataset/data/test.txt\", \"w\") as f:\n",
    "    for item in data:\n",
    "        f.write(str(item[\"diseases\"][\"name\"]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2}\n"
     ]
    }
   ],
   "source": [
    "my_set = set()\n",
    "my_set.add(1)\n",
    "my_set.add(2)\n",
    "my_set.add(1)\n",
    "\n",
    "print(my_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m51\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mset\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mset\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not callable"
     ]
    }
   ],
   "source": [
    "list = [1,2,3,1,5,6,4,3,51,2,1,]\n",
    "set = set(list)\n",
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "已写入 12 条数据到 dataset/data/test.txt\n"
     ]
    }
   ],
   "source": [
    "disease = set([1,23,15,5,1,65156151,1,15,16,56,165,1,56156,515,1,12,123])\n",
    "# 定义集合与文件的映射关系\n",
    "data_to_file = {\n",
    "    \"diseases\": (\"dataset/data/test.txt\", disease)\n",
    "}\n",
    "\n",
    "# 遍历映射关系，将数据写入文件\n",
    "for name, (filename, data) in data_to_file.items():\n",
    "    print(\"start\")\n",
    "    with open(filename, \"a\", encoding=\"utf-8\") as file:  # 使用追加模式\n",
    "        for item in data:\n",
    "            file.write(str(item) + \"\\n\")  # 每个数据占一行\n",
    "    print(f\"已写入 {len(data)} 条数据到 {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "m_model = models.resnet18()\n",
    "m_model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 1,000,000 行\n",
      "已处理: 2,000,000 行\n",
      "已处理: 3,000,000 行\n",
      "已处理: 4,000,000 行\n",
      "已处理: 5,000,000 行\n",
      "已处理: 6,000,000 行\n",
      "\n",
      "验证结果：\n",
      "train : ✓\n",
      "dev   : ✓\n",
      "test  : ✓\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_large_file(input_file, train_lines=5052395, dev_lines=660022, test_lines=716756):\n",
    "    \"\"\"\n",
    "    将大文件分割为训练集、开发集和测试集\n",
    "    参数：\n",
    "        input_file: 输入文件路径\n",
    "        train_lines: 训练集行数 (默认500万)\n",
    "        dev_lines: 开发集行数 (默认60万)\n",
    "        test_lines: 测试集行数 (默认60万)\n",
    "    \"\"\"\n",
    "    # 检查总行数是否足够\n",
    "    total_required = train_lines + dev_lines + test_lines\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    if total_lines < total_required:\n",
    "        print(f\"错误：文件至少需要 {total_required} 行，当前只有 {total_lines} 行\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 准备输出文件名\n",
    "    base_name = os.path.splitext(input_file)[0]\n",
    "    outputs = {\n",
    "        'train': (f\"{base_name}_train.txt\", train_lines),\n",
    "        'dev': (f\"{base_name}_dev.txt\", dev_lines),\n",
    "        'test': (f\"{base_name}_test.txt\", test_lines)\n",
    "    }\n",
    "\n",
    "    # 清空已存在的输出文件\n",
    "    for fname, _ in outputs.values():\n",
    "        if os.path.exists(fname):\n",
    "            os.remove(fname)\n",
    "\n",
    "    # 进度计数器\n",
    "    counter = 0\n",
    "    current_target = 'train'\n",
    "    remaining = {k: v[1] for k, v in outputs.items()}\n",
    "\n",
    "    # 开始处理\n",
    "    with open(input_file, 'r', encoding='utf-8') as src:\n",
    "        for line in tqdm(src):\n",
    "            # 写入当前目标文件\n",
    "            with open(outputs[current_target][0], 'a', encoding='utf-8') as dst:\n",
    "                dst.write(line)\n",
    "            \n",
    "            remaining[current_target] -= 1\n",
    "            counter += 1\n",
    "\n",
    "            # 显示进度\n",
    "            if counter % 1_000_000 == 0:\n",
    "                print(f\"已处理: {counter:,} 行\")\n",
    "\n",
    "            # 切换到下一个文件\n",
    "            if remaining[current_target] == 0:\n",
    "                if current_target == 'train':\n",
    "                    current_target = 'dev'\n",
    "                elif current_target == 'dev':\n",
    "                    current_target = 'test'\n",
    "                else:\n",
    "                    break  # 全部完成\n",
    "\n",
    "    # 验证结果\n",
    "    print(\"\\n验证结果：\")\n",
    "    for name, (fname, expected) in outputs.items():\n",
    "        actual = sum(1 for _ in open(fname, 'r', encoding='utf-8'))\n",
    "        status = \"✓\" if actual == expected else f\"✗ (应有{expected}, 实有{actual})\"\n",
    "        print(f\"{name.ljust(6)}: {status}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    input_file = \"ner_data_aug.txt\"\n",
    "    split_large_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "疾病: 感冒  \n",
      "症状: 头痛、发热、进食困难、便秘  \n",
      "部位: 牙齿  \n",
      "特征: 严重  \n",
      "疾病: 蛀牙\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "text = \"患者出现持续头痛和发热症状，牙齿蛀牙严重，进食困难而且便秘，感冒，蛀牙？\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "你是一个智能助手，负责识别用户句子中的实体，实体包括以下内容：\n",
    "- 疾病\n",
    "- 症状\n",
    "- 部位\n",
    "- 检查项目\n",
    "- 药品\n",
    "- 食物\n",
    "- 科室\n",
    "- 特征（比如轻微，严重）\n",
    "\n",
    "\n",
    "请根据以下句子识别实体：\n",
    "\"{text}\"\n",
    "你只需要识别出实体，然后告诉我检测出来的类别有哪些实体就行了，同一类别放在同一行，\n",
    "类别必须是上面我给出的，不要给其他的类别。\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.generate(model='qwen2.5:7b', prompt=prompt)\n",
    "print(response[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
